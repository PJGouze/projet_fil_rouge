{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4462d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grani\\anaconda3\\envs\\torch_NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# Import Deep Learning - Torch - models\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d8076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/Donnees_IA_2025.csv\", sep = \";\", encoding=\"latin1\")\n",
    "\n",
    "data_df= data_df.drop(columns=['Ordre', 'Code', 'Nom détaillé', 'Pays', 'Année récolte', 'Date mesure'])\n",
    "\n",
    "colonnes = data_df.columns\n",
    "colonnes_X = list(colonnes[:12])\n",
    "colonnes_Y = list(colonnes[12:])\n",
    "\n",
    "colonnes_cat = colonnes_X[:2]\n",
    "colonnes_num = colonnes_X[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7116e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_df[colonnes_X].values, data_df[colonnes_Y].values, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3aca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Tourteaux d'oléagineux\",\n",
       "        'Tourteau de soja, huile < 5 %, 48 % protéine + huile ', '88,2',\n",
       "        ..., '0,6', '5', '8,1'],\n",
       "       [\"Tourteaux d'oléagineux\",\n",
       "        'Tourteau de soja, huile < 5 %, 50 % protéine + huile ', '87,7',\n",
       "        ..., '0,4', '5,5', '9,5'],\n",
       "       ['Coproduits du blé',\n",
       "        'Drêches de blé de distillerie, amidon > 7 % ', '92,8', ...,\n",
       "        '3,1', '9,8', '5,4'],\n",
       "       ...,\n",
       "       [\"Tourteaux d'oléagineux\",\n",
       "        'Tourteau de soja, huile < 5 %, 48 % protéine + huile ', '90,5',\n",
       "        ..., '0,6', '5,2', '8,3'],\n",
       "       ['Coproduits du blé', 'Son de blé tendre ', '89,1', ..., '4,3',\n",
       "        '15,6', '7,2'],\n",
       "       ['Graines protéagineuses et oléagineuses', 'Graine de lin ',\n",
       "        '91,2', ..., '6', '5,5', '2,6']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca525a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Tourteaux d'oléagineux\", \"Tourteaux d'oléagineux\",\n",
       "       'Coproduits du blé', 'Graines protéagineuses et oléagineuses',\n",
       "       \"Coproduits d'animaux terrestres\", 'Coproduits du blé',\n",
       "       \"Tourteaux d'oléagineux\", 'Fourrages déshydratés',\n",
       "       \"Tourteaux d'oléagineux\", 'Céréales'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_train = X_train[:,0]\n",
    "X_cat_test = X_test[:,0]\n",
    "X_cat_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e944af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertModel(\n",
       "  (embeddings): CamembertEmbeddings(\n",
       "    (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): CamembertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x CamembertLayer(\n",
       "        (attention): CamembertAttention(\n",
       "          (self): CamembertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): CamembertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): CamembertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): CamembertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): CamembertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Défintion de l'appareil utilisé pour le traitement de l'apprentissage profond\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Définition du model CamemBert\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = AutoModel.from_pretrained(\"camembert-base\")\n",
    "model.to(device)\n",
    "# Défintion de l'inférence du modèle, nous ne sommes pas en phase d'apprentissage ici\n",
    "model.eval()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31a3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamembertEmbedder:\n",
    "    def __init__(self, model_name=\"camembert-base\", device=None, max_length=128, pooling=\"cls\"):\n",
    "        self.device = device or torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.max_length = max_length\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def _pool(self, outputs, attention_mask):\n",
    "        if self.pooling == \"cls\":\n",
    "            return outputs.last_hidden_state[:, 0, :]\n",
    "        elif self.pooling == \"mean\":\n",
    "            mask = attention_mask.unsqueeze(-1)\n",
    "            summed = (outputs.last_hidden_state * mask).sum(1)\n",
    "            counts = mask.sum(1)\n",
    "            return summed / counts\n",
    "        else:\n",
    "            raise ValueError(\"pooling must be 'cls' or 'mean'\")\n",
    "\n",
    "    def encode(self, texts, batch_size=16):\n",
    "        embeddings = []\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "\n",
    "            enc = self.tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            enc = {k: v.to(self.device) for k, v in enc.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**enc)\n",
    "\n",
    "            emb = self._pool(outputs, enc[\"attention_mask\"])\n",
    "            embeddings.append(emb.cpu().numpy())\n",
    "\n",
    "        return np.vstack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f26438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_b done\n"
     ]
    }
   ],
   "source": [
    "# Définition de l'objet avec pooling cls\n",
    "embedder_cls = CamembertEmbedder(pooling=\"cls\")\n",
    "\n",
    "# Encodage de l'emsemble de test et d'apprentissage\n",
    "X_train_emb = embedder_cls.encode(list(X_cat_train))\n",
    "print(\"X_train_b done\")\n",
    "X_test_emb  = embedder_cls.encode(list(X_cat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a858a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_emb[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3663c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "categorical_cols = colonnes_cat\n",
    "numerical_cols = colonnes_num\n",
    "# OneHotEncoder\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "X_cat = enc.fit_transform(data_df[categorical_cols])\n",
    "\n",
    "\n",
    "column_names = []\n",
    "for i, cat in enumerate(enc.categories_):\n",
    "    column_names.extend([f\"{categorical_cols[i]}_{c}\" for c in cat])\n",
    "\n",
    "X_cat_df = pd.DataFrame(X_cat, columns=column_names)\n",
    "\n",
    "data_final = pd.concat([ X_cat_df, data_df[numerical_cols], data_df[colonnes_Y]], axis=1)\n",
    "\n",
    "# Colonnes à retirer pour X et à garder pour y\n",
    "colonnes_cibles = [\n",
    "    'EB (kcal) kcal/kg brut', \n",
    "    'ED porc croissance (kcal) kcal/kg brut', \n",
    "    'EM porc croissance (kcal) kcal/kg brut', \n",
    "    'EN porc croissance (kcal) kcal/kg brut', \n",
    "    'EMAn coq (kcal) kcal/kg brut', \n",
    "    'EMAn poulet (kcal) kcal/kg brut', \n",
    "    'UFL 2018 par kg brut', \n",
    "    'UFV 2018 par kg brut', \n",
    "    'PDIA 2018 g_kg brut', \n",
    "    'PDI 2018 g_kg brut', \n",
    "    'BalProRu 2018 g_kg brut'\n",
    "]\n",
    "\n",
    "# Génération de la variable cible\n",
    "y = data_final[colonnes_cibles]\n",
    "\n",
    "# Génération des descripteurs\n",
    "X = data_final.drop(columns=colonnes_cibles)\n",
    "\n",
    "cols_num = ['MS % brut', 'PB % brut', 'CB % brut', 'MGR % brut', 'MM % brut', \n",
    "            'NDF % brut', 'ADF % brut', 'Lignine % brut', 'Amidon % brut', 'Sucres % brut']\n",
    "\n",
    "for col in cols_num:\n",
    "    X[col] = X[col].astype(str).str.replace(',', '.')\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce') \n",
    "\n",
    "for col in y.columns:\n",
    "    y[col] = y[col].astype(str).str.strip().str.replace(',', '.')\n",
    "    y[col] = pd.to_numeric(y[col], errors='coerce') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89875ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_from_input(model, encoder, X_columns, input_dict):\n",
    "    df = pd.DataFrame([input_dict])\n",
    "\n",
    "    # Séparer catégories et numériques\n",
    "    categorical_cols = encoder.feature_names_in_.tolist()\n",
    "    num_cols = [c for c in X_columns if c not in encoder.get_feature_names_out()]\n",
    "\n",
    "    X_cat = encoder.transform(df[categorical_cols])\n",
    "    X_cat_df = pd.DataFrame(X_cat, columns=encoder.get_feature_names_out())\n",
    "\n",
    "    X_num_df = df[num_cols]\n",
    "\n",
    "    X_final = pd.concat([X_cat_df, X_num_df], axis=1)\n",
    "\n",
    "    # Reorder columns\n",
    "    X_final = X_final[X_columns]\n",
    "\n",
    "    return model.predict(X_final)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
